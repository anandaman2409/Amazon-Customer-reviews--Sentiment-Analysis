{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datasetSplit.txt and datasetSentences.txt\n",
    "Segregate sentences based on sentence index and corresponding data set i.e 1 for train and 2 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "#List containing sentences belonging to train data set\n",
    "data_train=[]\n",
    "\n",
    "#List containing sentences belonging to test data set\n",
    "data_test=[]\n",
    "\n",
    "# List containing Sentence ids belonging to train data set\n",
    "trainIndex=[]\n",
    "\n",
    "# List containing Sentence ids belonging to test data set\n",
    "testIndex=[]\n",
    "\n",
    "with open(\"datasetSplit.txt\",\"r\") as f:\n",
    "    rd=list(csv.reader(f,delimiter=','))\n",
    "    count=0\n",
    "    for line in rd:\n",
    "        if count==0:\n",
    "            count=1\n",
    "            continue       \n",
    "        if line[1]=='1':\n",
    "            trainIndex.append(line[0])\n",
    "        if line[1]=='2':\n",
    "            testIndex.append(line[0])\n",
    "            \n",
    "with open(\"datasetSentences.txt\",\"r\") as f:\n",
    "    rd=list(csv.reader(f,delimiter='\\t'))\n",
    "    count=0\n",
    "    for line in rd:\n",
    "        if count==0:\n",
    "            count=1\n",
    "            continue        \n",
    "        if line[0] in trainIndex:\n",
    "            data_train.append(line[1])          \n",
    "        if line[0] in testIndex:         \n",
    "            data_test.append(line[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence\n",
       "0  The Rock is destined to be the 21st Century 's...\n",
       "1  The gorgeously elaborate continuation of `` Th...\n",
       "2  Singer\\/composer Bryan Adams contributes a sle...\n",
       "3  You 'd think by now America would have had eno...\n",
       "4               Yet the act is still charming here ."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting train and test list to Data Frames\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame(data_train,columns = ['Sentence'])\n",
    "df_test = pd.DataFrame(data_test,columns = ['Sentence'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create dictionary for Sentence : Phrase Id\n",
    "Appending 0 for phrase ID in all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentence_train = {}\n",
    "for item in data_train:\n",
    "    data_sentence_train[item]='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Replacing 0 with actual phrase Id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dictionary.txt\",\"r\") as f:\n",
    "    rd=list(csv.reader(f,delimiter='|'))\n",
    "    for line in rd:\n",
    "        if line[0] in data_sentence_train:\n",
    "            data_sentence_train[line[0]]=line[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create data frame from dict for Sentence: Phrase Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase_Id</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>226166</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>226300</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>225801</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14646</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14644</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Phrase_Id                                           Sentence\n",
       "0    226166  The Rock is destined to be the 21st Century 's...\n",
       "1    226300  The gorgeously elaborate continuation of `` Th...\n",
       "2    225801  Singer\\/composer Bryan Adams contributes a sle...\n",
       "3     14646  You 'd think by now America would have had eno...\n",
       "4     14644               Yet the act is still charming here ."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_reqd = pd.DataFrame.from_dict(data_sentence_train,orient ='index')\n",
    "df_reqd['Sentence']=df_reqd.index\n",
    "df_reqd.columns=['Phrase_Id','Sentence']\n",
    "df_reqd.index = np.arange(0, len(df_reqd))\n",
    "df_reqd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create dictionary for Phrase Id : Sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentiment={}\n",
    "with open(\"sentiment_labels.txt\",\"r\") as f:\n",
    "    rd=list(csv.reader(f,delimiter='|'))\n",
    "    count=0\n",
    "    for line in rd:\n",
    "        if count==0:\n",
    "            count=1\n",
    "            continue    \n",
    "        data_sentiment[line[0]]=line[1]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### create data frame \n",
    "1. Data Frame containing Sentiment and Phrase Id\n",
    "2. Data Frame containing Phrase Id and Sentence\n",
    "\n",
    "Goal -  To merge both data frames based on Phrase Id inorder to get sentiment value for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase_Id</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>226166</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>226300</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>225801</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14646</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14644</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Phrase_Id                                           Sentence\n",
       "0    226166  The Rock is destined to be the 21st Century 's...\n",
       "1    226300  The gorgeously elaborate continuation of `` Th...\n",
       "2    225801  Singer\\/composer Bryan Adams contributes a sle...\n",
       "3     14646  You 'd think by now America would have had eno...\n",
       "4     14644               Yet the act is still charming here ."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_sentiment = pd.DataFrame.from_dict(data_sentiment,orient ='index')\n",
    "df_data_sentiment['Phrase_Id']=df_data_sentiment.index\n",
    "df_data_sentiment.columns=['Sentiment','Phrase_Id']\n",
    "\n",
    "df_reqd = pd.DataFrame.from_dict(data_sentence_train,orient ='index')\n",
    "df_reqd['Sentence']=df_reqd.index\n",
    "df_reqd.columns=['Phrase_Id','Sentence']\n",
    "df_reqd.index = np.arange(0, len(df_reqd))\n",
    "df_reqd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Join both data frame based on Phrase Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>0.69444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>0.83333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>0.72222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The Rock is destined to be the 21st Century 's...   0.69444\n",
       "1  The gorgeously elaborate continuation of `` Th...   0.83333\n",
       "2  Singer\\/composer Bryan Adams contributes a sle...     0.625\n",
       "3  You 'd think by now America would have had eno...       0.5\n",
       "4               Yet the act is still charming here .   0.72222"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df_reqd, df_data_sentiment, on=['Phrase_Id'])\n",
    "df = df.drop(['Phrase_Id'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning labels to the sentiment values\n",
    "\n",
    "Sentiment            Label\n",
    "\n",
    "0-0.2     --------    1\n",
    "\n",
    "0.2-0.4   --------    2\n",
    "\n",
    "0.4-0.6   --------    3\n",
    "\n",
    "0.6-0.8   --------    4\n",
    "\n",
    "0.8-1.0   --------    5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeCategory(x):\n",
    "    if x>=0 and x<=0.2:\n",
    "        return 1\n",
    "    elif x>0.2 and x<=0.4:\n",
    "        return 2\n",
    "    elif x>0.4 and x<=0.6:\n",
    "        return 3\n",
    "    elif x>0.6 and x<=0.8:\n",
    "        return 4\n",
    "    elif x>0.8 and x<1:\n",
    "        return 5\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df['Sentiment']=df['Sentiment'].astype('float').apply(encodeCategory)\n",
    "df['Sentiment']=df['Sentiment'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence                      0\n",
       "Sentiment                     0\n",
       "Sentence_without_stopwords    0\n",
       "Sentence_lemmatized           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column containing sentences without stopwords\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['Sentence_without_stopwords'] = df['Sentence'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentence_without_stopwords</th>\n",
       "      <th>Sentence_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>4</td>\n",
       "      <td>The Rock destined 21st Century 's new `` Conan...</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>5</td>\n",
       "      <td>The gorgeously elaborate continuation `` The L...</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>4</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes slew ...</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>3</td>\n",
       "      <td>You 'd think America would enough plucky Briti...</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>4</td>\n",
       "      <td>Yet act still charming .</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment  \\\n",
       "0  The Rock is destined to be the 21st Century 's...          4   \n",
       "1  The gorgeously elaborate continuation of `` Th...          5   \n",
       "2  Singer\\/composer Bryan Adams contributes a sle...          4   \n",
       "3  You 'd think by now America would have had eno...          3   \n",
       "4               Yet the act is still charming here .          4   \n",
       "\n",
       "                          Sentence_without_stopwords  \\\n",
       "0  The Rock destined 21st Century 's new `` Conan...   \n",
       "1  The gorgeously elaborate continuation `` The L...   \n",
       "2  Singer\\/composer Bryan Adams contributes slew ...   \n",
       "3  You 'd think America would enough plucky Briti...   \n",
       "4                           Yet act still charming .   \n",
       "\n",
       "                                 Sentence_lemmatized  \n",
       "0  The Rock is destined to be the 21st Century 's...  \n",
       "1  The gorgeously elaborate continuation of `` Th...  \n",
       "2  Singer\\/composer Bryan Adams contributes a sle...  \n",
       "3  You 'd think by now America would have had eno...  \n",
       "4               Yet the act is still charming here .  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating column with lemmatized words\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "df['Sentence_lemmatized'] = df['Sentence'].apply(lambda x: ' '.join([wordnet.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create dictionary for Sentence : Phrase Id\n",
    "###### Appending 0 for phrase ID in all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentence_test = {}\n",
    "for item in data_test:\n",
    "    data_sentence_test[item]='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Replacing 0 with actual phrase Id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dictionary.txt\",\"r\") as f:\n",
    "    rd=list(csv.reader(f,delimiter='|'))\n",
    "    for line in rd:\n",
    "        if line[0] in data_sentence_test:\n",
    "            data_sentence_test[line[0]]=line[1]\n",
    "            \n",
    "count=0\n",
    "for key,value in data_sentence_test.items():\n",
    "    if value==0:\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create data frame from dict for Sentence: Phrase Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase_Id</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13995</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14123</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13999</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14498</td>\n",
       "      <td>The film provides some great insight into the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14351</td>\n",
       "      <td>Offers that rare combination of entertainment ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Phrase_Id                                           Sentence\n",
       "0     13995                     Effective but too-tepid biopic\n",
       "1     14123  If you sometimes like to go to the movies to h...\n",
       "2     13999  Emerges as something rare , an issue movie tha...\n",
       "3     14498  The film provides some great insight into the ...\n",
       "4     14351  Offers that rare combination of entertainment ..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_reqd_test = pd.DataFrame.from_dict(data_sentence_test,orient ='index')\n",
    "df_reqd_test['Sentence']=df_reqd_test.index\n",
    "df_reqd_test.columns=['Phrase_Id','Sentence']\n",
    "df_reqd_test.index = np.arange(0, len(df_reqd_test))\n",
    "df_reqd_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create dictionary for Phrase Id : Sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentiment_test={}\n",
    "with open(\"sentiment_labels.txt\",\"r\") as f:\n",
    "    rd=list(csv.reader(f,delimiter='|'))\n",
    "    count=0\n",
    "    for line in rd:\n",
    "        if count==0:\n",
    "            count=1\n",
    "            continue    \n",
    "        data_sentiment_test[line[0]]=line[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### create data frame from dict for Data_sentiments_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.44444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.42708</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment Phrase_Id\n",
       "0       0.5         0\n",
       "1       0.5         1\n",
       "2   0.44444         2\n",
       "3       0.5         3\n",
       "4   0.42708         4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_sentiment_test = pd.DataFrame.from_dict(data_sentiment_test,orient ='index')\n",
    "df_data_sentiment_test['Phrase_Id']=df_data_sentiment_test.index\n",
    "df_data_sentiment_test.columns=['Sentiment','Phrase_Id']\n",
    "df_data_sentiment_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Join both data frame based on Phrase Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_reqd_test, df_data_sentiment_test, on=['Phrase_Id'])\n",
    "df_test = df_test.drop(['Phrase_Id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence     0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Sentiment']=df_test['Sentiment'].astype('float').apply(encodeCategory)\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the data with sentence having lemmatized words\n",
    "\n",
    "data = df['Sentence_lemmatized']\n",
    "\n",
    "#Replace all the characters except a-z,A-Z with null\n",
    "data.replace(\"[^a-zA-Z]\",\" \",regex=True,inplace=True)\n",
    "\n",
    "df['Sentence_lemmatized']=df['Sentence_lemmatized'].str.lower()\n",
    "model_train_Sentence = list(df['Sentence_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the test data and lemmatizing before prediction\n",
    "\n",
    "df_test['Sentence_lemmatized'] = df_test['Sentence'].apply(lambda x: ' '.join([wordnet.lemmatize(word) for word in x.split()]))\n",
    "df_test['Sentence_lemmatized'].replace(\"[^a-zA-Z]\",\" \",regex=True,inplace=True)\n",
    "df_test['Sentence_lemmatized']=df_test['Sentence_lemmatized'].str.lower()\n",
    "\n",
    "\n",
    "test_transform = list(df_test['Sentence_lemmatized'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with different models to vectorize and will compare the accuracy\n",
    "\n",
    "1. Bag of words model\n",
    "2. TF-IDF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "countvector = CountVectorizer(ngram_range=(2,2))\n",
    "traindataset = countvector.fit_transform(model_train_Sentence)\n",
    "\n",
    "#Used Random Forest for classification\n",
    "\n",
    "randomClassifier = RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomClassifier.fit(traindataset,df['Sentiment'])\n",
    "\n",
    "test_transform = list(df_test['Sentence_lemmatized'])\n",
    "test_dataset = countvector.transform(test_transform)\n",
    "prediction = randomClassifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3253393665158371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(df_test['Sentiment'],prediction)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv = TfidfVectorizer()\n",
    "\n",
    "X= cv.fit_transform(model_train_Sentence)\n",
    "\n",
    "#Used Random Forest for classification\n",
    "\n",
    "randomClassifier = RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomClassifier.fit(X,df['Sentiment'])\n",
    "\n",
    "test_transform = list(df_test['Sentence_lemmatized'])\n",
    "test_dataset = cv.transform(test_transform)\n",
    "prediction = randomClassifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3918552036199095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(df_test['Sentiment'],prediction)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy\n",
    "\n",
    "1. Bag of Words - 0.3253393665158371\n",
    "2. TF-IDF model - 0.3918552036199095"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
